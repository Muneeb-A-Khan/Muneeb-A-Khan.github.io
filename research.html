<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Muneeb Ahmed Khan - Research Experience</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link rel="stylesheet" href="style.css">
     <script>
        // Configure Tailwind CSS - especially setting the Inter font
        tailwind.config = {
          theme: {
            extend: {
              fontFamily: {
                sans: ['Inter', 'sans-serif'],
              },
            }
          }
        }
      </script>
</head>
<body class="bg-gray-100 font-sans">

    <div class="container mx-auto max-w-4xl px-4 py-8">

        <header class="mb-8 text-center">
             <h1 class="text-3xl font-bold text-gray-900">Muneeb Ahmed Khan</h1>
             <p class="text-lg text-gray-600">Research Experience</p>
        </header>

        <nav class="bg-white p-4 rounded-lg shadow-md mb-8 sticky top-4 z-10">
            <ul class="flex justify-center space-x-6 md:space-x-10">
                <li><a href="index.html" class="text-gray-700 hover:text-blue-600 hover:border-b-2 hover:border-blue-600 pb-1 transition duration-150 ease-in-out">Home</a></li>
                <li><a href="publications.html" class="text-gray-700 hover:text-blue-600 hover:border-b-2 hover:border-blue-600 pb-1 transition duration-150 ease-in-out">Publications</a></li>
                <li><a href="research.html" class="text-blue-700 font-semibold border-b-2 border-blue-700 pb-1">Research Experience</a></li>
                <li><a href="experience.html" class="text-gray-700 hover:text-blue-600 hover:border-b-2 hover:border-blue-600 pb-1 transition duration-150 ease-in-out">Industrial Experience</a></li>
                <li><a href="cv.html" class="text-gray-700 hover:text-blue-600 hover:border-b-2 hover:border-blue-600 pb-1 transition duration-150 ease-in-out">CV</a></li>
            </ul>
        </nav>

        <main class="bg-white p-6 rounded-lg shadow-md">

            <section id="current-projects" class="mb-10">
                <h3 class="text-xl font-bold text-blue-800 border-b border-gray-300 pb-2 mb-4">Current Projects</h3>
                <div class="space-y-8"> <article> <h4 class="text-lg font-semibold text-gray-700 mb-1">Post-Processing Methods for Artifact Removal Using Machine Learning</h4>
                        <p class="text-sm text-gray-500 mb-2">Funding: <strong>Google Korea</strong> (2024-Present) | Affiliation: Google Korea & Pi Lab</p>
                        <p class="text-sm text-gray-500 mb-2">Tools: PyTorch, TensorFlow, OpenCV, NumPy, Pandas</p>
                        <ul class="list-disc list-inside text-gray-600 space-y-1 mt-2">
                            <li>Investigating machine learning techniques for suppressing noise, ghosting, and compression artifacts.</li>
                            <li>Optimizing artifact removal performance across diverse imaging modalities.</li>
                            <li>Designing deployment strategies suitable for mobile and resource-constrained environments.</li>
                        </ul>
                    </article>
                    <article>
                        <h4 class="text-lg font-semibold text-gray-700 mb-1">Multi-Modal Framework for Medical Condition Classification and Detection</h4>
                         <p class="text-sm text-gray-500 mb-2">Affiliation: Pi Lab</p>
                         <p class="text-sm text-gray-500 mb-2">Tools: PyTorch, TensorFlow, Keras, Grad-CAM, LIME, OpenCV</p>
                         <ul class="list-disc list-inside text-gray-600 space-y-1 mt-2">
                            <li>Developing multi-class detection system for brain tumors, COVID-19, pneumonia, and lung opacities.</li>
                            <li>Working on CNN architectures to handle ambiguous boundaries in medical images.</li>
                            <li>Optimizing model performance for resource-constrained clinical environments with explainability.</li>
                        </ul>
                    </article>
                     <article>
                        <h4 class="text-lg font-semibold text-gray-700 mb-1">Transformer-Enhanced Diffusion Models for Image Segmentation and Super-Resolution</h4>
                         <p class="text-sm text-gray-500 mb-2">Affiliation: Pi Lab</p>
                         <p class="text-sm text-gray-500 mb-2">Tools: PyTorch, TensorFlow, NumPy, Matplotlib</p>
                         <ul class="list-disc list-inside text-gray-600 space-y-1 mt-2">
                            <li>Developing diffusion techniques for image segmentation and resolution enhancement.</li>
                            <li>Integrating text-guided diffusion processes to enhance segmentation precision.</li>
                            <li>Validating performance across diverse imaging modalities for real-world applications.</li>
                        </ul>
                    </article>
                </div>
            </section>

            <section id="past-projects">
                 <h3 class="text-xl font-bold text-blue-800 border-b border-gray-300 pb-2 mb-4">Past Projects</h3>
                 <div class="space-y-8"> <article>
                        <h4 class="text-lg font-semibold text-gray-700 mb-1">Objective Quality Metrics for Ghosting Artifacts in Video and HDR Images</h4>
                        <p class="text-sm text-gray-500 mb-2">Funding: <strong>Google Korea</strong> (2023-2024) | Affiliation: Pi Lab</p>
                        <p class="text-sm text-gray-500 mb-2">Tools: PyTorch, OpenCV, scikit-image, NumPy, Pandas</p>
                        <ul class="list-disc list-inside text-gray-600 space-y-1 mt-2">
                       <li>Built a dataset of 2,500+ real images and annotated over 37,000 patches for spatial/temporal artifact detection.</li>
                       <li>Designed data pipelines for collection, annotation, and feature extraction from diverse imaging sources.</li>
                       <li>Developed a test framework simulating multiple camera noise conditions for robust artifact evaluation.</li>
                        <li>Developed a detection model evaluated using subjective and objective quality metrics.</li>
                        <li>Trained SOTA deep learning models for domain specific tasks (e.g ghosting artifacts, object detection).</li>
                        </ul>
                    </article>
                     <article>
                        <h4 class="text-lg font-semibold text-gray-700 mb-1">Multi-Scale Attention Model for Low-Light Image Enhancement</h4>
                        <p class="text-sm text-gray-500 mb-2">Affiliation: Pi Lab (2024)</p>
                        <p class="text-sm text-gray-500 mb-2">Tools: PyTorch, LoL Dataset v1/v2, GCP A100, SSIM, MS-SSIM, LPIPS</p>
                        <ul class="list-disc list-inside text-gray-600 space-y-1 mt-2">
                            <li>Designed a lightweight model (12M parameters) achieving 0.88 SSIM, 0.93 MS-SSIM, 0.207 LPIPS on LoL datasets using GCP A100.</li>
                            <li>Worked on integrating attention Mechanisms and transfer learning.</li>
                            <li>Implemented an adaptive enhancement pipeline balancing perceptual quality and computational efficiency.</li>
                            <li>Reviewed and implemented AAAI, CVPR, and ICCV research papers to optimize model performance.</li>
                        </ul>
                    </article>
                     <article>
                        <h4 class="text-lg font-semibold text-gray-700 mb-1">Brain Tumor Detection Using Magnetic Resonance Imaging</h4>
                         <p class="text-sm text-gray-500 mb-2">Affiliation: Pi Lab (2022-2024)</p>
                         <p class="text-sm text-gray-500 mb-2">Tools: TensorFlow, Keras, Grad-CAM, LIME</p>
                         <ul class="list-disc list-inside text-gray-600 space-y-1 mt-2">
                            <li>Developed a lightweight convolutional block architecture achieving 99.51% mAP with 17.2 ms inference speed.</li>
                            <li>Performed tumor segmentation, lesion classification, and anomaly detection in multi-modal MRI sequences.</li>
                            <li>Reduced false positives by 78% using explainable AI techniques (Grad-CAM, LIME).</li>
                        </ul>
                    </article>
                     <article>
                        <h4 class="text-lg font-semibold text-gray-700 mb-1">FireXplainNet: Interpretable Wildfire Detection System</h4>
                         <p class="text-sm text-gray-500 mb-2">Affiliation: Pi Lab (2023-2024)</p>
                         <p class="text-sm text-gray-500 mb-2">Tools: PyTorch, Grad-CAM, Matplotlib</p>
                         <ul class="list-disc list-inside text-gray-600 space-y-1 mt-2">
                            <li>Developed a lightweight interpretable CNN (5.3M parameters) for early wildfire detection.</li>
                            <li>Applied gradient-based attribution (Grad-CAM) for decision explainability in high-risk outdoor scenarios.</li>
                            <li>Achieved high accuracy under variable conditions; received Best Paper Award at KCC 2023.</li>
                        </ul>
                    </article>
                     <article>
                        <h4 class="text-lg font-semibold text-gray-700 mb-1">YOLO-Based Real-Time Object Detection and Tracking System</h4>
                         <p class="text-sm text-gray-500 mb-2">Affiliation: Pi Lab (2022-2023)</p>
                         <p class="text-sm text-gray-500 mb-2">Tools: YOLOv5, YOLO-NAS, DeepSORT, Kalman Filter, ByteTrack, PyTorch, OpenCV</p>
                         <ul class="list-disc list-inside text-gray-600 space-y-1 mt-2">
                            <li>Built a real-time multi-object detection and tracking system using YOLOv5/YOLO-NAS and DeepSORT.</li>
                            <li>Achieved mAP > 92% and 30+ FPS on COCO/MOT datasets, enabling real-time visual intelligence.</li>
                            <li>Leveraged GPU parallelization strategies to optimize inference performance.</li>
                        </ul>
                    </article>
                     <article>
                        <h4 class="text-lg font-semibold text-gray-700 mb-1">Traffic Sign Recognition with Advanced Neural Network Techniques</h4>
                         <p class="text-sm text-gray-500 mb-2">Affiliation: Pi Lab (2021-2023)</p>
                         <p class="text-sm text-gray-500 mb-2">Tools: TensorFlow, OpenCV, Grad-CAM, LIME, GTSRB, ITSD, PTSD</p>
                         <ul class="list-disc list-inside text-gray-600 space-y-1 mt-2">
                           <li>Developed an interpretable CNN (2.6M parameters) achieving 98.4% accuracy and 74.34 ms inference.</li>
                           <li>Streamlined ML model development and deployment with MLflow for tracking and reproducibility.</li>
                           <li>Optimize GPU acceleration and parallel processing to optimize the system performance.</li>
                           <li>Worked on explainable and adversarial robust traffic sign classification to improve model accuracy.</li>
                        </ul>
                    </article>
                </div>
            </section>

        </main>

        <footer class="text-center text-gray-500 text-sm mt-8">
            &copy; <span id="current-year"></span> Muneeb Ahmed Khan.
        </footer>
        <script>
            // Set current year in footer
            document.getElementById('current-year').textContent = new Date().getFullYear();
        </script>

    </div>

</body>
</html>
